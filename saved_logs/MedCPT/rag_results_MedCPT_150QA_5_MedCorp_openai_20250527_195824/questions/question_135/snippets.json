[
    {
        "id": "pubmed23n0074_5895",
        "title": "The consumer's risk in clinical trials.",
        "content": "In any formal statistical test of the null hypothesis (the statement that a population parameter is equal to a specific value), there are two possible types of error. Type 1 or alpha error has occurred if the investigator rejects the null hypothesis when it is true. For example, an experimental treatment is declared an advance over standard treatment when it is not. Type 2 or beta error has occurred if the null hypothesis is not rejected when it is false. In this case, the investigator concludes that the experimental treatment is no different than the standard when it actually is. The two types of error can be conceptualized, respectively, as the consumer's risk and the producer's risk. In many reports of clinical trial methodology, it is the producer's risk that is emphasized. It is understandable why producer's risk would be of concern to authors of clinical studies. There are, however, numerous potential sources of consumer's risk. It is the latter type of risk that is the primary subject of this report.",
        "contents": "The consumer's risk in clinical trials. In any formal statistical test of the null hypothesis (the statement that a population parameter is equal to a specific value), there are two possible types of error. Type 1 or alpha error has occurred if the investigator rejects the null hypothesis when it is true. For example, an experimental treatment is declared an advance over standard treatment when it is not. Type 2 or beta error has occurred if the null hypothesis is not rejected when it is false. In this case, the investigator concludes that the experimental treatment is no different than the standard when it actually is. The two types of error can be conceptualized, respectively, as the consumer's risk and the producer's risk. In many reports of clinical trial methodology, it is the producer's risk that is emphasized. It is understandable why producer's risk would be of concern to authors of clinical studies. There are, however, numerous potential sources of consumer's risk. It is the latter type of risk that is the primary subject of this report.",
        "PMID": 2222896
    },
    {
        "id": "wiki20220301en012_3970",
        "title": "Power of a test",
        "content": "A significance criterion is a statement of how unlikely a positive result must be, if the null hypothesis of no effect is true, for the null hypothesis to be rejected. The most commonly used criteria are probabilities of 0.05 (5%, 1 in 20), 0.01 (1%, 1 in 100), and 0.001 (0.1%, 1 in 1000). If the criterion is 0.05, the probability of the data implying an effect at least as large as the observed effect when the null hypothesis is true must be less than 0.05, for the null hypothesis of no effect to be rejected. One easy way to increase the power of a test is to carry out a less conservative test by using a larger significance criterion, for example 0.10 instead of 0.05 . This increases the chance of rejecting the null hypothesis (obtaining a statistically significant result) when the null hypothesis is false; that is, it reduces the risk of a type II error (false negative regarding whether an effect exists). But it also increases the risk of obtaining a statistically significant result",
        "contents": "Power of a test. A significance criterion is a statement of how unlikely a positive result must be, if the null hypothesis of no effect is true, for the null hypothesis to be rejected. The most commonly used criteria are probabilities of 0.05 (5%, 1 in 20), 0.01 (1%, 1 in 100), and 0.001 (0.1%, 1 in 1000). If the criterion is 0.05, the probability of the data implying an effect at least as large as the observed effect when the null hypothesis is true must be less than 0.05, for the null hypothesis of no effect to be rejected. One easy way to increase the power of a test is to carry out a less conservative test by using a larger significance criterion, for example 0.10 instead of 0.05 . This increases the chance of rejecting the null hypothesis (obtaining a statistically significant result) when the null hypothesis is false; that is, it reduces the risk of a type II error (false negative regarding whether an effect exists). But it also increases the risk of obtaining a statistically significant result",
        "wiki_id": "238695"
    },
    {
        "id": "Surgery_Schwartz_14028",
        "title": "Surgery_Schwartz",
        "content": "the null hypothesis is rejected given that it is true. The error rate may also be referred to as the significance level, and often a value of 0.05, or 5%, is frequently used in the literature.Type II Error. A type II error is the failure to reject the null hypothesis when the null hypothesis is false. This error may also be referred to as a false negative. The type II error rate is denoted by the Greek letter \u03b2 (beta), and is related to the power of a study. Power can range from 0 to 1, and as power increases, there is decreasing probability of making a type II error. Power is related to three main factors: (a) the statistical significance criterion of the study, (b) the magnitude of the effect of interest, and (c) the sample size used to detect the effect. Power analysis can be used to calculate the minimum sample size required for a study so that one can be likely to detect an effect of a given size.P ValuesThe P value was an innovation most closely associated with Sir Ronald",
        "contents": "Surgery_Schwartz. the null hypothesis is rejected given that it is true. The error rate may also be referred to as the significance level, and often a value of 0.05, or 5%, is frequently used in the literature.Type II Error. A type II error is the failure to reject the null hypothesis when the null hypothesis is false. This error may also be referred to as a false negative. The type II error rate is denoted by the Greek letter \u03b2 (beta), and is related to the power of a study. Power can range from 0 to 1, and as power increases, there is decreasing probability of making a type II error. Power is related to three main factors: (a) the statistical significance criterion of the study, (b) the magnitude of the effect of interest, and (c) the sample size used to detect the effect. Power analysis can be used to calculate the minimum sample size required for a study so that one can be likely to detect an effect of a given size.P ValuesThe P value was an innovation most closely associated with Sir Ronald"
    },
    {
        "id": "article-95301_8",
        "title": "Hypothesis Testing, P Values, Confidence Intervals, and Significance -- Issues of Concern -- P Values",
        "content": "For either statement, if the threshold had been set at 0.05, the null hypothesis (that there was no relationship) should be rejected, and we should conclude significant differences. Noticeably, as can be seen in the\u00a02 statements above, some researchers report findings with < or >, and others provide an exact p-value\u00a0(0.000001) but never\u00a00 [6] . When examining research, readers should understand how p values are reported. The best practice is to report all p values for all variables within a study design rather than only providing p values for variables with significant findings. [7] Including all p values provides evidence for study validity and limits suspicion for selective reporting/data mining.",
        "contents": "Hypothesis Testing, P Values, Confidence Intervals, and Significance -- Issues of Concern -- P Values. For either statement, if the threshold had been set at 0.05, the null hypothesis (that there was no relationship) should be rejected, and we should conclude significant differences. Noticeably, as can be seen in the\u00a02 statements above, some researchers report findings with < or >, and others provide an exact p-value\u00a0(0.000001) but never\u00a00 [6] . When examining research, readers should understand how p values are reported. The best practice is to report all p values for all variables within a study design rather than only providing p values for variables with significant findings. [7] Including all p values provides evidence for study validity and limits suspicion for selective reporting/data mining."
    },
    {
        "id": "Surgery_Schwartz_14027",
        "title": "Surgery_Schwartz",
        "content": "statistical testing requires declaration of a null hypothesis, usually corresponding to the \u201cdefault\u201d state (i.e., no difference or the patient is healthy). The alternative hypothesis would then negate the stated null hypothesis (i.e., there is a dif-ference or the patient is unhealthy). The result of a statistical significance test may either reject or accept the null hypothesis, and this result can correspond with the true state (a correct deci-sion) or not correspond with the true state (an error). Two types of error are possible (Table 51-3).Type I Error. A type I error occurs when the null hypothesis is rejected but is actually true in the population. This may also be referred to as a false positive. The type I error rate, denoted by the Greek letter \u03b1 (alpha), is the probability that the null hypothesis is rejected given that it is true. The error rate may also be referred to as the significance level, and often a value of 0.05, or 5%, is frequently used in the literature.Type",
        "contents": "Surgery_Schwartz. statistical testing requires declaration of a null hypothesis, usually corresponding to the \u201cdefault\u201d state (i.e., no difference or the patient is healthy). The alternative hypothesis would then negate the stated null hypothesis (i.e., there is a dif-ference or the patient is unhealthy). The result of a statistical significance test may either reject or accept the null hypothesis, and this result can correspond with the true state (a correct deci-sion) or not correspond with the true state (an error). Two types of error are possible (Table 51-3).Type I Error. A type I error occurs when the null hypothesis is rejected but is actually true in the population. This may also be referred to as a false positive. The type I error rate, denoted by the Greek letter \u03b1 (alpha), is the probability that the null hypothesis is rejected given that it is true. The error rate may also be referred to as the significance level, and often a value of 0.05, or 5%, is frequently used in the literature.Type"
    }
]