[
    {
        "id": "pubmed23n0074_5895",
        "title": "The consumer's risk in clinical trials.",
        "content": "In any formal statistical test of the null hypothesis (the statement that a population parameter is equal to a specific value), there are two possible types of error. Type 1 or alpha error has occurred if the investigator rejects the null hypothesis when it is true. For example, an experimental treatment is declared an advance over standard treatment when it is not. Type 2 or beta error has occurred if the null hypothesis is not rejected when it is false. In this case, the investigator concludes that the experimental treatment is no different than the standard when it actually is. The two types of error can be conceptualized, respectively, as the consumer's risk and the producer's risk. In many reports of clinical trial methodology, it is the producer's risk that is emphasized. It is understandable why producer's risk would be of concern to authors of clinical studies. There are, however, numerous potential sources of consumer's risk. It is the latter type of risk that is the primary subject of this report.",
        "contents": "The consumer's risk in clinical trials. In any formal statistical test of the null hypothesis (the statement that a population parameter is equal to a specific value), there are two possible types of error. Type 1 or alpha error has occurred if the investigator rejects the null hypothesis when it is true. For example, an experimental treatment is declared an advance over standard treatment when it is not. Type 2 or beta error has occurred if the null hypothesis is not rejected when it is false. In this case, the investigator concludes that the experimental treatment is no different than the standard when it actually is. The two types of error can be conceptualized, respectively, as the consumer's risk and the producer's risk. In many reports of clinical trial methodology, it is the producer's risk that is emphasized. It is understandable why producer's risk would be of concern to authors of clinical studies. There are, however, numerous potential sources of consumer's risk. It is the latter type of risk that is the primary subject of this report.",
        "PMID": 2222896
    },
    {
        "id": "Surgery_Schwartz_14027",
        "title": "Surgery_Schwartz",
        "content": "statistical testing requires declaration of a null hypothesis, usually corresponding to the \u201cdefault\u201d state (i.e., no difference or the patient is healthy). The alternative hypothesis would then negate the stated null hypothesis (i.e., there is a dif-ference or the patient is unhealthy). The result of a statistical significance test may either reject or accept the null hypothesis, and this result can correspond with the true state (a correct deci-sion) or not correspond with the true state (an error). Two types of error are possible (Table 51-3).Type I Error. A type I error occurs when the null hypothesis is rejected but is actually true in the population. This may also be referred to as a false positive. The type I error rate, denoted by the Greek letter \u03b1 (alpha), is the probability that the null hypothesis is rejected given that it is true. The error rate may also be referred to as the significance level, and often a value of 0.05, or 5%, is frequently used in the literature.Type",
        "contents": "Surgery_Schwartz. statistical testing requires declaration of a null hypothesis, usually corresponding to the \u201cdefault\u201d state (i.e., no difference or the patient is healthy). The alternative hypothesis would then negate the stated null hypothesis (i.e., there is a dif-ference or the patient is unhealthy). The result of a statistical significance test may either reject or accept the null hypothesis, and this result can correspond with the true state (a correct deci-sion) or not correspond with the true state (an error). Two types of error are possible (Table 51-3).Type I Error. A type I error occurs when the null hypothesis is rejected but is actually true in the population. This may also be referred to as a false positive. The type I error rate, denoted by the Greek letter \u03b1 (alpha), is the probability that the null hypothesis is rejected given that it is true. The error rate may also be referred to as the significance level, and often a value of 0.05, or 5%, is frequently used in the literature.Type"
    },
    {
        "id": "wiki20220301en012_3970",
        "title": "Power of a test",
        "content": "A significance criterion is a statement of how unlikely a positive result must be, if the null hypothesis of no effect is true, for the null hypothesis to be rejected. The most commonly used criteria are probabilities of 0.05 (5%, 1 in 20), 0.01 (1%, 1 in 100), and 0.001 (0.1%, 1 in 1000). If the criterion is 0.05, the probability of the data implying an effect at least as large as the observed effect when the null hypothesis is true must be less than 0.05, for the null hypothesis of no effect to be rejected. One easy way to increase the power of a test is to carry out a less conservative test by using a larger significance criterion, for example 0.10 instead of 0.05 . This increases the chance of rejecting the null hypothesis (obtaining a statistically significant result) when the null hypothesis is false; that is, it reduces the risk of a type II error (false negative regarding whether an effect exists). But it also increases the risk of obtaining a statistically significant result",
        "contents": "Power of a test. A significance criterion is a statement of how unlikely a positive result must be, if the null hypothesis of no effect is true, for the null hypothesis to be rejected. The most commonly used criteria are probabilities of 0.05 (5%, 1 in 20), 0.01 (1%, 1 in 100), and 0.001 (0.1%, 1 in 1000). If the criterion is 0.05, the probability of the data implying an effect at least as large as the observed effect when the null hypothesis is true must be less than 0.05, for the null hypothesis of no effect to be rejected. One easy way to increase the power of a test is to carry out a less conservative test by using a larger significance criterion, for example 0.10 instead of 0.05 . This increases the chance of rejecting the null hypothesis (obtaining a statistically significant result) when the null hypothesis is false; that is, it reduces the risk of a type II error (false negative regarding whether an effect exists). But it also increases the risk of obtaining a statistically significant result",
        "wiki_id": "238695"
    },
    {
        "id": "article-29464_6",
        "title": "Statistical Significance -- Introduction",
        "content": "What does this mean? The P value is not the probability of the null hypothesis itself. It is the probability that, if the study were repeated an infinite number of times, one would expect the findings to be as, or more extreme, than the one calculated in\u00a0this test. Therefore, the P value of 0.02 would signify that 2% of the infinite tests would find a result at least as extreme as the one in this study. Given that\u00a0the null hypothesis states that\u00a0there\u00a0is no significant change in blood pressure if the patient is or is not taking the new medication, we can assume that this statement is false, as 98% of the infinite studies would find that there was indeed a reduction in blood pressure. However, as the P value implies, there is a chance that this is false, and there truly is no effect of the medication on the blood pressure. However, as the researcher prespecified\u00a0an acceptable confidence level with an alpha of 0.05, and the P value is 0.02, less than the acceptable alpha of 0.05, the researcher rejects the null hypothesis. By rejecting the null hypothesis, the\u00a0researcher accepts the alternative hypothesis. The researcher rejects the idea that there is no difference in systolic blood pressure with\u00a0the new medication and accepts a difference of at least 10 mm Hg in systolic blood pressure when taking the new\u00a0medication.",
        "contents": "Statistical Significance -- Introduction. What does this mean? The P value is not the probability of the null hypothesis itself. It is the probability that, if the study were repeated an infinite number of times, one would expect the findings to be as, or more extreme, than the one calculated in\u00a0this test. Therefore, the P value of 0.02 would signify that 2% of the infinite tests would find a result at least as extreme as the one in this study. Given that\u00a0the null hypothesis states that\u00a0there\u00a0is no significant change in blood pressure if the patient is or is not taking the new medication, we can assume that this statement is false, as 98% of the infinite studies would find that there was indeed a reduction in blood pressure. However, as the P value implies, there is a chance that this is false, and there truly is no effect of the medication on the blood pressure. However, as the researcher prespecified\u00a0an acceptable confidence level with an alpha of 0.05, and the P value is 0.02, less than the acceptable alpha of 0.05, the researcher rejects the null hypothesis. By rejecting the null hypothesis, the\u00a0researcher accepts the alternative hypothesis. The researcher rejects the idea that there is no difference in systolic blood pressure with\u00a0the new medication and accepts a difference of at least 10 mm Hg in systolic blood pressure when taking the new\u00a0medication."
    },
    {
        "id": "article-95301_4",
        "title": "Hypothesis Testing, P Values, Confidence Intervals, and Significance -- Issues of Concern -- Hypothesis Testing",
        "content": "Regarding p values, the likelihood of finding a statistically significant effect increases as the number of individuals enrolled in a study (the sample size) increases. With very large sample sizes, the p-value can be very low, and there are significant differences in reducing symptoms for Disease A between Drug 23 and Drug 22. The null hypothesis is deemed true until a study presents significant data to support rejecting the null hypothesis. Based on the results, the investigators either reject the null hypothesis (if they found significant differences or associations) or fail to reject\u00a0the null hypothesis (they could not prove that there were significant differences or associations).",
        "contents": "Hypothesis Testing, P Values, Confidence Intervals, and Significance -- Issues of Concern -- Hypothesis Testing. Regarding p values, the likelihood of finding a statistically significant effect increases as the number of individuals enrolled in a study (the sample size) increases. With very large sample sizes, the p-value can be very low, and there are significant differences in reducing symptoms for Disease A between Drug 23 and Drug 22. The null hypothesis is deemed true until a study presents significant data to support rejecting the null hypothesis. Based on the results, the investigators either reject the null hypothesis (if they found significant differences or associations) or fail to reject\u00a0the null hypothesis (they could not prove that there were significant differences or associations)."
    }
]