[
    {
        "id": "pubmed23n0074_5895",
        "title": "The consumer's risk in clinical trials.",
        "content": "In any formal statistical test of the null hypothesis (the statement that a population parameter is equal to a specific value), there are two possible types of error. Type 1 or alpha error has occurred if the investigator rejects the null hypothesis when it is true. For example, an experimental treatment is declared an advance over standard treatment when it is not. Type 2 or beta error has occurred if the null hypothesis is not rejected when it is false. In this case, the investigator concludes that the experimental treatment is no different than the standard when it actually is. The two types of error can be conceptualized, respectively, as the consumer's risk and the producer's risk. In many reports of clinical trial methodology, it is the producer's risk that is emphasized. It is understandable why producer's risk would be of concern to authors of clinical studies. There are, however, numerous potential sources of consumer's risk. It is the latter type of risk that is the primary subject of this report.",
        "contents": "The consumer's risk in clinical trials. In any formal statistical test of the null hypothesis (the statement that a population parameter is equal to a specific value), there are two possible types of error. Type 1 or alpha error has occurred if the investigator rejects the null hypothesis when it is true. For example, an experimental treatment is declared an advance over standard treatment when it is not. Type 2 or beta error has occurred if the null hypothesis is not rejected when it is false. In this case, the investigator concludes that the experimental treatment is no different than the standard when it actually is. The two types of error can be conceptualized, respectively, as the consumer's risk and the producer's risk. In many reports of clinical trial methodology, it is the producer's risk that is emphasized. It is understandable why producer's risk would be of concern to authors of clinical studies. There are, however, numerous potential sources of consumer's risk. It is the latter type of risk that is the primary subject of this report.",
        "PMID": 2222896
    },
    {
        "id": "Surgery_Schwartz_14027",
        "title": "Surgery_Schwartz",
        "content": "statistical testing requires declaration of a null hypothesis, usually corresponding to the \u201cdefault\u201d state (i.e., no difference or the patient is healthy). The alternative hypothesis would then negate the stated null hypothesis (i.e., there is a dif-ference or the patient is unhealthy). The result of a statistical significance test may either reject or accept the null hypothesis, and this result can correspond with the true state (a correct deci-sion) or not correspond with the true state (an error). Two types of error are possible (Table 51-3).Type I Error. A type I error occurs when the null hypothesis is rejected but is actually true in the population. This may also be referred to as a false positive. The type I error rate, denoted by the Greek letter \u03b1 (alpha), is the probability that the null hypothesis is rejected given that it is true. The error rate may also be referred to as the significance level, and often a value of 0.05, or 5%, is frequently used in the literature.Type",
        "contents": "Surgery_Schwartz. statistical testing requires declaration of a null hypothesis, usually corresponding to the \u201cdefault\u201d state (i.e., no difference or the patient is healthy). The alternative hypothesis would then negate the stated null hypothesis (i.e., there is a dif-ference or the patient is unhealthy). The result of a statistical significance test may either reject or accept the null hypothesis, and this result can correspond with the true state (a correct deci-sion) or not correspond with the true state (an error). Two types of error are possible (Table 51-3).Type I Error. A type I error occurs when the null hypothesis is rejected but is actually true in the population. This may also be referred to as a false positive. The type I error rate, denoted by the Greek letter \u03b1 (alpha), is the probability that the null hypothesis is rejected given that it is true. The error rate may also be referred to as the significance level, and often a value of 0.05, or 5%, is frequently used in the literature.Type"
    },
    {
        "id": "wiki20220301en012_3970",
        "title": "Power of a test",
        "content": "A significance criterion is a statement of how unlikely a positive result must be, if the null hypothesis of no effect is true, for the null hypothesis to be rejected. The most commonly used criteria are probabilities of 0.05 (5%, 1 in 20), 0.01 (1%, 1 in 100), and 0.001 (0.1%, 1 in 1000). If the criterion is 0.05, the probability of the data implying an effect at least as large as the observed effect when the null hypothesis is true must be less than 0.05, for the null hypothesis of no effect to be rejected. One easy way to increase the power of a test is to carry out a less conservative test by using a larger significance criterion, for example 0.10 instead of 0.05 . This increases the chance of rejecting the null hypothesis (obtaining a statistically significant result) when the null hypothesis is false; that is, it reduces the risk of a type II error (false negative regarding whether an effect exists). But it also increases the risk of obtaining a statistically significant result",
        "contents": "Power of a test. A significance criterion is a statement of how unlikely a positive result must be, if the null hypothesis of no effect is true, for the null hypothesis to be rejected. The most commonly used criteria are probabilities of 0.05 (5%, 1 in 20), 0.01 (1%, 1 in 100), and 0.001 (0.1%, 1 in 1000). If the criterion is 0.05, the probability of the data implying an effect at least as large as the observed effect when the null hypothesis is true must be less than 0.05, for the null hypothesis of no effect to be rejected. One easy way to increase the power of a test is to carry out a less conservative test by using a larger significance criterion, for example 0.10 instead of 0.05 . This increases the chance of rejecting the null hypothesis (obtaining a statistically significant result) when the null hypothesis is false; that is, it reduces the risk of a type II error (false negative regarding whether an effect exists). But it also increases the risk of obtaining a statistically significant result",
        "wiki_id": "238695"
    },
    {
        "id": "First_Aid_Step1_262",
        "title": "First_Aid_Step1",
        "content": "Asymmetry with longer tail on right. Negative skew Typically, mean < median < mode. Mode Asymmetry with longer tail on left. Statistical hypotheses Outcomes of statistical hypothesis testing Correct result Stating that there is an effect or difference when Reality one exists (null hypothesis rejected in favor of HH alternative hypothesis). Stating that there is no effect or difference when none exists (null hypothesis not rejected). Blue shading = correct result. Confidence interval Range of values within which the true mean of the population is expected to fall, with a specified probability. CI for sample mean = x\u00af \u00b1 Z(SE) The 95% CI (corresponding to \u03b1 = .05) is often used. As sample size increases, CI narrows. For the 95% CI, Z = 1.96. For the 99% CI, Z = 2.58. If the 95% CI for a mean difference between 2 variables includes 0, then there is no significant difference and H0 is not rejected. If the 95% CI for odds ratio or relative risk includes 1, H0 is not rejected.",
        "contents": "First_Aid_Step1. Asymmetry with longer tail on right. Negative skew Typically, mean < median < mode. Mode Asymmetry with longer tail on left. Statistical hypotheses Outcomes of statistical hypothesis testing Correct result Stating that there is an effect or difference when Reality one exists (null hypothesis rejected in favor of HH alternative hypothesis). Stating that there is no effect or difference when none exists (null hypothesis not rejected). Blue shading = correct result. Confidence interval Range of values within which the true mean of the population is expected to fall, with a specified probability. CI for sample mean = x\u00af \u00b1 Z(SE) The 95% CI (corresponding to \u03b1 = .05) is often used. As sample size increases, CI narrows. For the 95% CI, Z = 1.96. For the 99% CI, Z = 2.58. If the 95% CI for a mean difference between 2 variables includes 0, then there is no significant difference and H0 is not rejected. If the 95% CI for odds ratio or relative risk includes 1, H0 is not rejected."
    },
    {
        "id": "article-29464_6",
        "title": "Statistical Significance -- Introduction",
        "content": "What does this mean? The P value is not the probability of the null hypothesis itself. It is the probability that, if the study were repeated an infinite number of times, one would expect the findings to be as, or more extreme, than the one calculated in\u00a0this test. Therefore, the P value of 0.02 would signify that 2% of the infinite tests would find a result at least as extreme as the one in this study. Given that\u00a0the null hypothesis states that\u00a0there\u00a0is no significant change in blood pressure if the patient is or is not taking the new medication, we can assume that this statement is false, as 98% of the infinite studies would find that there was indeed a reduction in blood pressure. However, as the P value implies, there is a chance that this is false, and there truly is no effect of the medication on the blood pressure. However, as the researcher prespecified\u00a0an acceptable confidence level with an alpha of 0.05, and the P value is 0.02, less than the acceptable alpha of 0.05, the researcher rejects the null hypothesis. By rejecting the null hypothesis, the\u00a0researcher accepts the alternative hypothesis. The researcher rejects the idea that there is no difference in systolic blood pressure with\u00a0the new medication and accepts a difference of at least 10 mm Hg in systolic blood pressure when taking the new\u00a0medication.",
        "contents": "Statistical Significance -- Introduction. What does this mean? The P value is not the probability of the null hypothesis itself. It is the probability that, if the study were repeated an infinite number of times, one would expect the findings to be as, or more extreme, than the one calculated in\u00a0this test. Therefore, the P value of 0.02 would signify that 2% of the infinite tests would find a result at least as extreme as the one in this study. Given that\u00a0the null hypothesis states that\u00a0there\u00a0is no significant change in blood pressure if the patient is or is not taking the new medication, we can assume that this statement is false, as 98% of the infinite studies would find that there was indeed a reduction in blood pressure. However, as the P value implies, there is a chance that this is false, and there truly is no effect of the medication on the blood pressure. However, as the researcher prespecified\u00a0an acceptable confidence level with an alpha of 0.05, and the P value is 0.02, less than the acceptable alpha of 0.05, the researcher rejects the null hypothesis. By rejecting the null hypothesis, the\u00a0researcher accepts the alternative hypothesis. The researcher rejects the idea that there is no difference in systolic blood pressure with\u00a0the new medication and accepts a difference of at least 10 mm Hg in systolic blood pressure when taking the new\u00a0medication."
    },
    {
        "id": "article-95301_4",
        "title": "Hypothesis Testing, P Values, Confidence Intervals, and Significance -- Issues of Concern -- Hypothesis Testing",
        "content": "Regarding p values, the likelihood of finding a statistically significant effect increases as the number of individuals enrolled in a study (the sample size) increases. With very large sample sizes, the p-value can be very low, and there are significant differences in reducing symptoms for Disease A between Drug 23 and Drug 22. The null hypothesis is deemed true until a study presents significant data to support rejecting the null hypothesis. Based on the results, the investigators either reject the null hypothesis (if they found significant differences or associations) or fail to reject\u00a0the null hypothesis (they could not prove that there were significant differences or associations).",
        "contents": "Hypothesis Testing, P Values, Confidence Intervals, and Significance -- Issues of Concern -- Hypothesis Testing. Regarding p values, the likelihood of finding a statistically significant effect increases as the number of individuals enrolled in a study (the sample size) increases. With very large sample sizes, the p-value can be very low, and there are significant differences in reducing symptoms for Disease A between Drug 23 and Drug 22. The null hypothesis is deemed true until a study presents significant data to support rejecting the null hypothesis. Based on the results, the investigators either reject the null hypothesis (if they found significant differences or associations) or fail to reject\u00a0the null hypothesis (they could not prove that there were significant differences or associations)."
    },
    {
        "id": "wiki20220301en001_160059",
        "title": "Statistical hypothesis testing",
        "content": "To slightly formalize intuition: radioactivity is suspected if the Geiger-count with the suitcase is among or exceeds the greatest (5% or 1%) of the Geiger-counts made with ambient radiation alone. This makes no assumptions about the distribution of counts. Many ambient radiation observations are required to obtain good probability estimates for rare events. The test described here is more fully the null-hypothesis statistical significance test. The null hypothesis represents what we would believe by default, before seeing any evidence. Statistical significance is a possible finding of the test, declared when the observed sample is unlikely to have occurred by chance if the null hypothesis were true. The name of the test describes its formulation and its possible outcome. One characteristic of the test is its crisp decision: to reject or not reject the null hypothesis. A calculated value is compared to a threshold, which is determined from the tolerable risk of error.",
        "contents": "Statistical hypothesis testing. To slightly formalize intuition: radioactivity is suspected if the Geiger-count with the suitcase is among or exceeds the greatest (5% or 1%) of the Geiger-counts made with ambient radiation alone. This makes no assumptions about the distribution of counts. Many ambient radiation observations are required to obtain good probability estimates for rare events. The test described here is more fully the null-hypothesis statistical significance test. The null hypothesis represents what we would believe by default, before seeing any evidence. Statistical significance is a possible finding of the test, declared when the observed sample is unlikely to have occurred by chance if the null hypothesis were true. The name of the test describes its formulation and its possible outcome. One characteristic of the test is its crisp decision: to reject or not reject the null hypothesis. A calculated value is compared to a threshold, which is determined from the tolerable risk of error.",
        "wiki_id": "30284"
    },
    {
        "id": "wiki20220301en001_160031",
        "title": "Statistical hypothesis testing",
        "content": "Select a significance level (\u03b1), a probability threshold below which the null hypothesis will be rejected. Common values are 5% and 1%. The distribution of the test statistic under the null hypothesis partitions the possible values of T into those for which the null hypothesis is rejected\u2014the so-called critical region\u2014and those for which it is not. The probability of the critical region is \u03b1. In the case of a composite null hypothesis, the maximal probability of the critical region is \u03b1. Compute from the observations the observed value tobs of the test statistic T. Decide to either reject the null hypothesis in favor of the alternative or not reject it. The decision rule is to reject the null hypothesis H0 if the observed value tobs is in the critical region, and not to reject the null hypothesis otherwise.",
        "contents": "Statistical hypothesis testing. Select a significance level (\u03b1), a probability threshold below which the null hypothesis will be rejected. Common values are 5% and 1%. The distribution of the test statistic under the null hypothesis partitions the possible values of T into those for which the null hypothesis is rejected\u2014the so-called critical region\u2014and those for which it is not. The probability of the critical region is \u03b1. In the case of a composite null hypothesis, the maximal probability of the critical region is \u03b1. Compute from the observations the observed value tobs of the test statistic T. Decide to either reject the null hypothesis in favor of the alternative or not reject it. The decision rule is to reject the null hypothesis H0 if the observed value tobs is in the critical region, and not to reject the null hypothesis otherwise.",
        "wiki_id": "30284"
    },
    {
        "id": "pubmed23n0067_17484",
        "title": "A statistical method for assessing a threshold in epidemiological studies.",
        "content": "I describe a method for estimating and testing a threshold value in epidemiological studies. A threshold effect indicates an association between a risk factor and a defined outcome above the threshold value but none below it. An important field of application is occupational medicine where, for a lot of chemical compounds and other agents which are non-carcinogenic health hazards, so-called threshold limit values or TLVs are specified. The method is presented within the framework of the logistic regression model, which is widely used in the analysis of the relationship between some explanatory variables and a dependent dichotomous outcome. In most available programs for this and also for other models the concept of a threshold is disregarded. The method for assessing a threshold consists of an estimation procedure using the maximum-likelihood technique and a test procedure based on the likelihood-ratio statistic R, following under the null hypothesis (no threshold) a quasi one-sided chi 2 distribution with one degree of freedom. This use of this distribution is supported by a simulation study. The method is applied to data from an epidemiological study of the relationship between occupational dust exposure and chronic bronchitic reactions. The results are confirmed by bootstrap resampling.",
        "contents": "A statistical method for assessing a threshold in epidemiological studies. I describe a method for estimating and testing a threshold value in epidemiological studies. A threshold effect indicates an association between a risk factor and a defined outcome above the threshold value but none below it. An important field of application is occupational medicine where, for a lot of chemical compounds and other agents which are non-carcinogenic health hazards, so-called threshold limit values or TLVs are specified. The method is presented within the framework of the logistic regression model, which is widely used in the analysis of the relationship between some explanatory variables and a dependent dichotomous outcome. In most available programs for this and also for other models the concept of a threshold is disregarded. The method for assessing a threshold consists of an estimation procedure using the maximum-likelihood technique and a test procedure based on the likelihood-ratio statistic R, following under the null hypothesis (no threshold) a quasi one-sided chi 2 distribution with one degree of freedom. This use of this distribution is supported by a simulation study. The method is applied to data from an epidemiological study of the relationship between occupational dust exposure and chronic bronchitic reactions. The results are confirmed by bootstrap resampling.",
        "PMID": 2028118
    },
    {
        "id": "article-18323_4",
        "title": "T Test -- Issues of Concern",
        "content": "These variations of the student's t-test use observed or collected data to calculate a test statistic, which can then be used to calculate a p-value. Often misinterpreted, the p-value is equal to the probability of collecting data that is at least as extreme as the observed data in the study, assuming that the null hypothesis is true. [3] Examples best illustrate this concept, as in the article's questions. Often, a threshold value is set before the study (equal to the alpha mentioned above); if the resulting p-value is below the preset threshold, there is sufficient evidence to reject the null hypothesis.",
        "contents": "T Test -- Issues of Concern. These variations of the student's t-test use observed or collected data to calculate a test statistic, which can then be used to calculate a p-value. Often misinterpreted, the p-value is equal to the probability of collecting data that is at least as extreme as the observed data in the study, assuming that the null hypothesis is true. [3] Examples best illustrate this concept, as in the article's questions. Often, a threshold value is set before the study (equal to the alpha mentioned above); if the resulting p-value is below the preset threshold, there is sufficient evidence to reject the null hypothesis."
    },
    {
        "id": "Surgery_Schwartz_14028",
        "title": "Surgery_Schwartz",
        "content": "the null hypothesis is rejected given that it is true. The error rate may also be referred to as the significance level, and often a value of 0.05, or 5%, is frequently used in the literature.Type II Error. A type II error is the failure to reject the null hypothesis when the null hypothesis is false. This error may also be referred to as a false negative. The type II error rate is denoted by the Greek letter \u03b2 (beta), and is related to the power of a study. Power can range from 0 to 1, and as power increases, there is decreasing probability of making a type II error. Power is related to three main factors: (a) the statistical significance criterion of the study, (b) the magnitude of the effect of interest, and (c) the sample size used to detect the effect. Power analysis can be used to calculate the minimum sample size required for a study so that one can be likely to detect an effect of a given size.P ValuesThe P value was an innovation most closely associated with Sir Ronald",
        "contents": "Surgery_Schwartz. the null hypothesis is rejected given that it is true. The error rate may also be referred to as the significance level, and often a value of 0.05, or 5%, is frequently used in the literature.Type II Error. A type II error is the failure to reject the null hypothesis when the null hypothesis is false. This error may also be referred to as a false negative. The type II error rate is denoted by the Greek letter \u03b2 (beta), and is related to the power of a study. Power can range from 0 to 1, and as power increases, there is decreasing probability of making a type II error. Power is related to three main factors: (a) the statistical significance criterion of the study, (b) the magnitude of the effect of interest, and (c) the sample size used to detect the effect. Power analysis can be used to calculate the minimum sample size required for a study so that one can be likely to detect an effect of a given size.P ValuesThe P value was an innovation most closely associated with Sir Ronald"
    },
    {
        "id": "article-18323_2",
        "title": "T Test -- Issues of Concern",
        "content": "If you believe these numbers are wrong (alternate hypothesis) or want to test the original hypothesis, you could collect blood from a set of subjects, measure the sodium concentration in each sample, and then take the mean of this set. If the mean is 140.1 mEq/L, you probably do not have convincing evidence that the above numbers are faulty (since 140 and 140.1 are\u00a0fairly close). Thus, you would fail to reject the null hypothesis. However, if your sample has a mean of 70 mEq/L,\u00a0this could be preliminary evidence (assuming rigorous methodology) and could end up rejecting the null hypothesis. The decision-making process would be trickier if the sample's mean were 134 or 150 mEq/L. The t-test can reduce subjective influence when testing a null hypothesis. Before testing a hypothesis, researchers should choose the alpha and beta values of the test. Loosely, the alpha parameter determines the threshold for false-positive results (eg, if the mean serum sodium concentration is 140 mEq/L, but the t-test rejects the original hypothesis in favor of your new hypothesis). The beta parameter determines the threshold for false-negative results (eg, if the true mean serum sodium concentration is 200 mEq/L, but the t-test fails to reject the old hypothesis). Methods of alpha and beta selection are outside this\u00a0topic's scope.",
        "contents": "T Test -- Issues of Concern. If you believe these numbers are wrong (alternate hypothesis) or want to test the original hypothesis, you could collect blood from a set of subjects, measure the sodium concentration in each sample, and then take the mean of this set. If the mean is 140.1 mEq/L, you probably do not have convincing evidence that the above numbers are faulty (since 140 and 140.1 are\u00a0fairly close). Thus, you would fail to reject the null hypothesis. However, if your sample has a mean of 70 mEq/L,\u00a0this could be preliminary evidence (assuming rigorous methodology) and could end up rejecting the null hypothesis. The decision-making process would be trickier if the sample's mean were 134 or 150 mEq/L. The t-test can reduce subjective influence when testing a null hypothesis. Before testing a hypothesis, researchers should choose the alpha and beta values of the test. Loosely, the alpha parameter determines the threshold for false-positive results (eg, if the mean serum sodium concentration is 140 mEq/L, but the t-test rejects the original hypothesis in favor of your new hypothesis). The beta parameter determines the threshold for false-negative results (eg, if the true mean serum sodium concentration is 200 mEq/L, but the t-test fails to reject the old hypothesis). Methods of alpha and beta selection are outside this\u00a0topic's scope."
    },
    {
        "id": "article-95301_8",
        "title": "Hypothesis Testing, P Values, Confidence Intervals, and Significance -- Issues of Concern -- P Values",
        "content": "For either statement, if the threshold had been set at 0.05, the null hypothesis (that there was no relationship) should be rejected, and we should conclude significant differences. Noticeably, as can be seen in the\u00a02 statements above, some researchers report findings with < or >, and others provide an exact p-value\u00a0(0.000001) but never\u00a00 [6] . When examining research, readers should understand how p values are reported. The best practice is to report all p values for all variables within a study design rather than only providing p values for variables with significant findings. [7] Including all p values provides evidence for study validity and limits suspicion for selective reporting/data mining.",
        "contents": "Hypothesis Testing, P Values, Confidence Intervals, and Significance -- Issues of Concern -- P Values. For either statement, if the threshold had been set at 0.05, the null hypothesis (that there was no relationship) should be rejected, and we should conclude significant differences. Noticeably, as can be seen in the\u00a02 statements above, some researchers report findings with < or >, and others provide an exact p-value\u00a0(0.000001) but never\u00a00 [6] . When examining research, readers should understand how p values are reported. The best practice is to report all p values for all variables within a study design rather than only providing p values for variables with significant findings. [7] Including all p values provides evidence for study validity and limits suspicion for selective reporting/data mining."
    },
    {
        "id": "pubmed23n0076_7938",
        "title": "Review of the two sample t tests.",
        "content": "The t test is a valuable statistical manipulation of moderate strength to determine whether a significant difference exists between the means of two groups, either paired or unpaired. Generally, the larger the t value, the greater chance of its statistical significance. Sample size also will influence the point at which t becomes significant, that is, the larger the size of n, the smaller the t required to become significant. As the number of degrees of freedom becomes larger, a smaller t value is sufficient to reject the null hypothesis, and as variability increases, the true chance for significant difference decreases. It should be noted that a common error in the use of the t test occurs with excessive repetition of the test on the same dataset. A resultant type 1 error will be introduced that incorrectly concludes that significant differences have been demonstrated when, in fact, they have resulted not from significance but from repeated statistical application. In other words, if a .05 level of significance is used repeatedly on a dataset, the investigator is assuming that there is a 1 in 20 chance of finding a significant difference when there is no true difference between variables. It becomes obvious that if 20 repeated applications of the t test were performed, one would expect to find one significant difference by chance alone when no true difference exists. If more than 10 applications of the t test are being conducted on the same dataset, the investigator should lower the level of significance (.01) on each individual t test of the entire set so fewer null hypotheses are rejected. t Tests numbering 40 to 50 should have an alpha level of .005. An alternative approach would be to consult a statistician and use multivariate statistical procedures.",
        "contents": "Review of the two sample t tests. The t test is a valuable statistical manipulation of moderate strength to determine whether a significant difference exists between the means of two groups, either paired or unpaired. Generally, the larger the t value, the greater chance of its statistical significance. Sample size also will influence the point at which t becomes significant, that is, the larger the size of n, the smaller the t required to become significant. As the number of degrees of freedom becomes larger, a smaller t value is sufficient to reject the null hypothesis, and as variability increases, the true chance for significant difference decreases. It should be noted that a common error in the use of the t test occurs with excessive repetition of the test on the same dataset. A resultant type 1 error will be introduced that incorrectly concludes that significant differences have been demonstrated when, in fact, they have resulted not from significance but from repeated statistical application. In other words, if a .05 level of significance is used repeatedly on a dataset, the investigator is assuming that there is a 1 in 20 chance of finding a significant difference when there is no true difference between variables. It becomes obvious that if 20 repeated applications of the t test were performed, one would expect to find one significant difference by chance alone when no true difference exists. If more than 10 applications of the t test are being conducted on the same dataset, the investigator should lower the level of significance (.01) on each individual t test of the entire set so fewer null hypotheses are rejected. t Tests numbering 40 to 50 should have an alpha level of .005. An alternative approach would be to consult a statistician and use multivariate statistical procedures.",
        "PMID": 2285714
    },
    {
        "id": "pubmed23n0061_11001",
        "title": "A meta-analysis of reported correlations between prognostic factors in breast cancer: does axillary lymph node metastasis represent biology or chronology?",
        "content": "A statistical overview of published results on correlations between various prognostic factors in breast cancer was undertaken. A distinction was made between clinical (or anatomical) prognostic factors--namely, axillary lymph node status and tumour size--and eight different biological prognostic factors. The latter included: tumour grade, oestrogen and progesterone receptor status, thymidine labelling index, DNA ploidy, S-phase fraction, epidermal growth factor receptor expression and c-erbB-2 gene amplification (or overexpression). 139 articles were eligible for review which reported a total of 432 individual correlations. A simple form of meta-analysis was employed: the counting method, in which the number of studies achieving a statistically significant correlation or not were counted. For each possible correlation examined, the proportion of studies showing a statistically significant correlation was calculated and an exact binomial 99% confidence interval determined for that proportion. If the 99% confidence interval included 5% (the proportion of correlations that would be expected to be statistically significant if the null hypothesis was true), it was taken as failing to exclude the null hypothesis of a zero correlation, while if it excluded 5% it was taken as rejecting the null hypothesis of a zero correlation. A broad agreement was found among published reports on the existence of a statistically significant correlation between the various biological prognostic factors in breast cancer. Of the 20 correlations examined, 18 had a 99% confidence interval excluding 5%, thus rejecting the null hypothesis of a zero correlation. On the other hand, a completely different result was obtained when reports on possible correlations between lymph node status and tumour size on the one hand and the eight biological prognostic factors on the other were analysed. Of the 16 correlations examined, 13 had a 99% confidence interval including 5%, failing to reject the null hypothesis of a zero correlation. These observations suggest the hypothesis that the prognostic influence of node status and tumour size cannot be explained by an analysis of the biology of breast cancer; and is compatible with the contention that axillary node status is merely a reflection of the relative chronological age of breast cancer.",
        "contents": "A meta-analysis of reported correlations between prognostic factors in breast cancer: does axillary lymph node metastasis represent biology or chronology? A statistical overview of published results on correlations between various prognostic factors in breast cancer was undertaken. A distinction was made between clinical (or anatomical) prognostic factors--namely, axillary lymph node status and tumour size--and eight different biological prognostic factors. The latter included: tumour grade, oestrogen and progesterone receptor status, thymidine labelling index, DNA ploidy, S-phase fraction, epidermal growth factor receptor expression and c-erbB-2 gene amplification (or overexpression). 139 articles were eligible for review which reported a total of 432 individual correlations. A simple form of meta-analysis was employed: the counting method, in which the number of studies achieving a statistically significant correlation or not were counted. For each possible correlation examined, the proportion of studies showing a statistically significant correlation was calculated and an exact binomial 99% confidence interval determined for that proportion. If the 99% confidence interval included 5% (the proportion of correlations that would be expected to be statistically significant if the null hypothesis was true), it was taken as failing to exclude the null hypothesis of a zero correlation, while if it excluded 5% it was taken as rejecting the null hypothesis of a zero correlation. A broad agreement was found among published reports on the existence of a statistically significant correlation between the various biological prognostic factors in breast cancer. Of the 20 correlations examined, 18 had a 99% confidence interval excluding 5%, thus rejecting the null hypothesis of a zero correlation. On the other hand, a completely different result was obtained when reports on possible correlations between lymph node status and tumour size on the one hand and the eight biological prognostic factors on the other were analysed. Of the 16 correlations examined, 13 had a 99% confidence interval including 5%, failing to reject the null hypothesis of a zero correlation. These observations suggest the hypothesis that the prognostic influence of node status and tumour size cannot be explained by an analysis of the biology of breast cancer; and is compatible with the contention that axillary node status is merely a reflection of the relative chronological age of breast cancer.",
        "PMID": 1838260
    }
]