[
    {
        "id": "wiki20220301en012_3970",
        "title": "Power of a test",
        "content": "A significance criterion is a statement of how unlikely a positive result must be, if the null hypothesis of no effect is true, for the null hypothesis to be rejected. The most commonly used criteria are probabilities of 0.05 (5%, 1 in 20), 0.01 (1%, 1 in 100), and 0.001 (0.1%, 1 in 1000). If the criterion is 0.05, the probability of the data implying an effect at least as large as the observed effect when the null hypothesis is true must be less than 0.05, for the null hypothesis of no effect to be rejected. One easy way to increase the power of a test is to carry out a less conservative test by using a larger significance criterion, for example 0.10 instead of 0.05 . This increases the chance of rejecting the null hypothesis (obtaining a statistically significant result) when the null hypothesis is false; that is, it reduces the risk of a type II error (false negative regarding whether an effect exists). But it also increases the risk of obtaining a statistically significant result",
        "contents": "Power of a test. A significance criterion is a statement of how unlikely a positive result must be, if the null hypothesis of no effect is true, for the null hypothesis to be rejected. The most commonly used criteria are probabilities of 0.05 (5%, 1 in 20), 0.01 (1%, 1 in 100), and 0.001 (0.1%, 1 in 1000). If the criterion is 0.05, the probability of the data implying an effect at least as large as the observed effect when the null hypothesis is true must be less than 0.05, for the null hypothesis of no effect to be rejected. One easy way to increase the power of a test is to carry out a less conservative test by using a larger significance criterion, for example 0.10 instead of 0.05 . This increases the chance of rejecting the null hypothesis (obtaining a statistically significant result) when the null hypothesis is false; that is, it reduces the risk of a type II error (false negative regarding whether an effect exists). But it also increases the risk of obtaining a statistically significant result",
        "wiki_id": "238695"
    },
    {
        "id": "wiki20220301en001_160031",
        "title": "Statistical hypothesis testing",
        "content": "Select a significance level (α), a probability threshold below which the null hypothesis will be rejected. Common values are 5% and 1%. The distribution of the test statistic under the null hypothesis partitions the possible values of T into those for which the null hypothesis is rejected—the so-called critical region—and those for which it is not. The probability of the critical region is α. In the case of a composite null hypothesis, the maximal probability of the critical region is α. Compute from the observations the observed value tobs of the test statistic T. Decide to either reject the null hypothesis in favor of the alternative or not reject it. The decision rule is to reject the null hypothesis H0 if the observed value tobs is in the critical region, and not to reject the null hypothesis otherwise.",
        "contents": "Statistical hypothesis testing. Select a significance level (α), a probability threshold below which the null hypothesis will be rejected. Common values are 5% and 1%. The distribution of the test statistic under the null hypothesis partitions the possible values of T into those for which the null hypothesis is rejected—the so-called critical region—and those for which it is not. The probability of the critical region is α. In the case of a composite null hypothesis, the maximal probability of the critical region is α. Compute from the observations the observed value tobs of the test statistic T. Decide to either reject the null hypothesis in favor of the alternative or not reject it. The decision rule is to reject the null hypothesis H0 if the observed value tobs is in the critical region, and not to reject the null hypothesis otherwise.",
        "wiki_id": "30284"
    },
    {
        "id": "wiki20220301en001_160059",
        "title": "Statistical hypothesis testing",
        "content": "To slightly formalize intuition: radioactivity is suspected if the Geiger-count with the suitcase is among or exceeds the greatest (5% or 1%) of the Geiger-counts made with ambient radiation alone. This makes no assumptions about the distribution of counts. Many ambient radiation observations are required to obtain good probability estimates for rare events. The test described here is more fully the null-hypothesis statistical significance test. The null hypothesis represents what we would believe by default, before seeing any evidence. Statistical significance is a possible finding of the test, declared when the observed sample is unlikely to have occurred by chance if the null hypothesis were true. The name of the test describes its formulation and its possible outcome. One characteristic of the test is its crisp decision: to reject or not reject the null hypothesis. A calculated value is compared to a threshold, which is determined from the tolerable risk of error.",
        "contents": "Statistical hypothesis testing. To slightly formalize intuition: radioactivity is suspected if the Geiger-count with the suitcase is among or exceeds the greatest (5% or 1%) of the Geiger-counts made with ambient radiation alone. This makes no assumptions about the distribution of counts. Many ambient radiation observations are required to obtain good probability estimates for rare events. The test described here is more fully the null-hypothesis statistical significance test. The null hypothesis represents what we would believe by default, before seeing any evidence. Statistical significance is a possible finding of the test, declared when the observed sample is unlikely to have occurred by chance if the null hypothesis were true. The name of the test describes its formulation and its possible outcome. One characteristic of the test is its crisp decision: to reject or not reject the null hypothesis. A calculated value is compared to a threshold, which is determined from the tolerable risk of error.",
        "wiki_id": "30284"
    },
    {
        "id": "wiki20220301en001_160030",
        "title": "Statistical hypothesis testing",
        "content": "Decide which test is appropriate, and state the relevant test statistic T. Derive the distribution of the test statistic under the null hypothesis from the assumptions. In standard cases this will be a well-known result. For example, the test statistic might follow a Student's t distribution with known degrees of freedom, or a normal distribution with known mean and variance. If the distribution of the test statistic is completely fixed by the null hypothesis we call the hypothesis simple, otherwise it is called composite. Select a significance level (α), a probability threshold below which the null hypothesis will be rejected. Common values are 5% and 1%.",
        "contents": "Statistical hypothesis testing. Decide which test is appropriate, and state the relevant test statistic T. Derive the distribution of the test statistic under the null hypothesis from the assumptions. In standard cases this will be a well-known result. For example, the test statistic might follow a Student's t distribution with known degrees of freedom, or a normal distribution with known mean and variance. If the distribution of the test statistic is completely fixed by the null hypothesis we call the hypothesis simple, otherwise it is called composite. Select a significance level (α), a probability threshold below which the null hypothesis will be rejected. Common values are 5% and 1%.",
        "wiki_id": "30284"
    },
    {
        "id": "wiki20220301en009_34434",
        "title": "Statistical significance",
        "content": "Role in statistical hypothesis testing Statistical significance plays a pivotal role in statistical hypothesis testing. It is used to determine whether the null hypothesis should be rejected or retained. The null hypothesis is the default assumption that nothing happened or changed. For the null hypothesis to be rejected, an observed result has to be statistically significant, i.e. the observed p-value is less than the pre-specified significance level . To determine whether a result is statistically significant, a researcher calculates a p-value, which is the probability of observing an effect of the same magnitude or more extreme given that the null hypothesis is true. The null hypothesis is rejected if the p-value is less than (or equal to) a predetermined level, . is also called the significance level, and is the probability of rejecting the null hypothesis given that it is true (a type I error). It is usually set at or below 5%.",
        "contents": "Statistical significance. Role in statistical hypothesis testing Statistical significance plays a pivotal role in statistical hypothesis testing. It is used to determine whether the null hypothesis should be rejected or retained. The null hypothesis is the default assumption that nothing happened or changed. For the null hypothesis to be rejected, an observed result has to be statistically significant, i.e. the observed p-value is less than the pre-specified significance level . To determine whether a result is statistically significant, a researcher calculates a p-value, which is the probability of observing an effect of the same magnitude or more extreme given that the null hypothesis is true. The null hypothesis is rejected if the p-value is less than (or equal to) a predetermined level, . is also called the significance level, and is the probability of rejecting the null hypothesis given that it is true (a type I error). It is usually set at or below 5%.",
        "wiki_id": "160995"
    },
    {
        "id": "wiki20220301en009_34433",
        "title": "Statistical significance",
        "content": "Despite his initial suggestion of 0.05 as a significance level, Fisher did not intend this cutoff value to be fixed. In his 1956 publication Statistical Methods and Scientific Inference, he recommended that significance levels be set according to specific circumstances. Related concepts The significance level is the threshold for below which the null hypothesis is rejected even though by assumption it were true, and something else is going on. This means that is also the probability of mistakenly rejecting the null hypothesis, if the null hypothesis is true. This is also called false positive and type I error. Sometimes researchers talk about the confidence level instead. This is the probability of not rejecting the null hypothesis given that it is true. Confidence levels and confidence intervals were introduced by Neyman in 1937. Role in statistical hypothesis testing",
        "contents": "Statistical significance. Despite his initial suggestion of 0.05 as a significance level, Fisher did not intend this cutoff value to be fixed. In his 1956 publication Statistical Methods and Scientific Inference, he recommended that significance levels be set according to specific circumstances. Related concepts The significance level is the threshold for below which the null hypothesis is rejected even though by assumption it were true, and something else is going on. This means that is also the probability of mistakenly rejecting the null hypothesis, if the null hypothesis is true. This is also called false positive and type I error. Sometimes researchers talk about the confidence level instead. This is the probability of not rejecting the null hypothesis given that it is true. Confidence levels and confidence intervals were introduced by Neyman in 1937. Role in statistical hypothesis testing",
        "wiki_id": "160995"
    },
    {
        "id": "wiki20220301en000_50375",
        "title": "Biostatistics",
        "content": "Statistical considerations Power and statistical error When testing a hypothesis, there are two types of statistic errors possible: Type I error and Type II error. The type I error or false positive is the incorrect rejection of a true null hypothesis and the type II error or false negative is the failure to reject a false null hypothesis. The significance level denoted by α is the type I error rate and should be chosen before performing the test. The type II error rate is denoted by β and statistical power of the test is 1 − β. p-value The p-value is the probability of obtaining results as extreme as or more extreme than those observed, assuming the null hypothesis (H0) is true. It is also called the calculated probability. It is common to confuse the p-value with the significance level (α), but, the α is a predefined threshold for calling significant results. If p is less than α, the null hypothesis (H0) is rejected. Multiple testing",
        "contents": "Biostatistics. Statistical considerations Power and statistical error When testing a hypothesis, there are two types of statistic errors possible: Type I error and Type II error. The type I error or false positive is the incorrect rejection of a true null hypothesis and the type II error or false negative is the failure to reject a false null hypothesis. The significance level denoted by α is the type I error rate and should be chosen before performing the test. The type II error rate is denoted by β and statistical power of the test is 1 − β. p-value The p-value is the probability of obtaining results as extreme as or more extreme than those observed, assuming the null hypothesis (H0) is true. It is also called the calculated probability. It is common to confuse the p-value with the significance level (α), but, the α is a predefined threshold for calling significant results. If p is less than α, the null hypothesis (H0) is rejected. Multiple testing",
        "wiki_id": "3878"
    },
    {
        "id": "wiki20220301en011_96668",
        "title": "Null hypothesis",
        "content": "\"The statement being tested in a test of statistical significance is called the null hypothesis. The test of significance is designed to assess the strength of the evidence against the null hypothesis. Usually, the null hypothesis is a statement of 'no effect' or 'no difference'.\" It is often symbolized as H0. The statement that is being tested against the null hypothesis is the alternative hypothesis. Symbols include H1 and Ha. Statistical significance test: \"Very roughly, the procedure for deciding goes like this: Take a random sample from the population. If the sample data are consistent with the null hypothesis, then do not reject the null hypothesis; if the sample data are inconsistent with the null hypothesis, then reject the null hypothesis and conclude that the alternative hypothesis is true.\" The following adds context and nuance to the basic definitions.",
        "contents": "Null hypothesis. \"The statement being tested in a test of statistical significance is called the null hypothesis. The test of significance is designed to assess the strength of the evidence against the null hypothesis. Usually, the null hypothesis is a statement of 'no effect' or 'no difference'.\" It is often symbolized as H0. The statement that is being tested against the null hypothesis is the alternative hypothesis. Symbols include H1 and Ha. Statistical significance test: \"Very roughly, the procedure for deciding goes like this: Take a random sample from the population. If the sample data are consistent with the null hypothesis, then do not reject the null hypothesis; if the sample data are inconsistent with the null hypothesis, then reject the null hypothesis and conclude that the alternative hypothesis is true.\" The following adds context and nuance to the basic definitions.",
        "wiki_id": "226673"
    },
    {
        "id": "wiki20220301en001_160035",
        "title": "Statistical hypothesis testing",
        "content": "If the p-value is less than the chosen significance threshold (equivalently, if the observed test statistic is in the critical region), then we say the null hypothesis is rejected at the chosen level of significance. If the p-value is not less than the chosen significance threshold (equivalently, if the observed test statistic is outside the critical region), then the null hypothesis is not rejected. In the Lady tasting tea example (below), Fisher required the Lady to properly categorize all of the cups of tea to justify the conclusion that the result was unlikely to result from chance. His test revealed that if the lady was effectively guessing at random (the null hypothesis), there was a 1.4% chance that the observed results (perfectly ordered tea) would occur.",
        "contents": "Statistical hypothesis testing. If the p-value is less than the chosen significance threshold (equivalently, if the observed test statistic is in the critical region), then we say the null hypothesis is rejected at the chosen level of significance. If the p-value is not less than the chosen significance threshold (equivalently, if the observed test statistic is outside the critical region), then the null hypothesis is not rejected. In the Lady tasting tea example (below), Fisher required the Lady to properly categorize all of the cups of tea to justify the conclusion that the result was unlikely to result from chance. His test revealed that if the lady was effectively guessing at random (the null hypothesis), there was a 1.4% chance that the observed results (perfectly ordered tea) would occur.",
        "wiki_id": "30284"
    },
    {
        "id": "wiki20220301en001_160015",
        "title": "Statistical hypothesis testing",
        "content": "A statistical hypothesis test is a method of statistical inference used to determine a possible conclusion from two different, and likely conflicting, hypotheses. In a statistical hypothesis test, a null hypothesis and an alternative hypothesis is proposed for the probability distribution of the data. If the sample obtained has a probability of occurrence less than the pre-specified threshold probability, the significance level, given the null hypothesis is true, the difference between the sample and the null hypothesis is deemed statistically significant. The hypothesis test may then lead to the rejection of null hypothesis and acceptance of alternate hypothesis. The process of distinguishing between the null hypothesis and the alternative hypothesis is aided by considering Type I error and Type II error which are controlled by the pre-specified significance level.",
        "contents": "Statistical hypothesis testing. A statistical hypothesis test is a method of statistical inference used to determine a possible conclusion from two different, and likely conflicting, hypotheses. In a statistical hypothesis test, a null hypothesis and an alternative hypothesis is proposed for the probability distribution of the data. If the sample obtained has a probability of occurrence less than the pre-specified threshold probability, the significance level, given the null hypothesis is true, the difference between the sample and the null hypothesis is deemed statistically significant. The hypothesis test may then lead to the rejection of null hypothesis and acceptance of alternate hypothesis. The process of distinguishing between the null hypothesis and the alternative hypothesis is aided by considering Type I error and Type II error which are controlled by the pre-specified significance level.",
        "wiki_id": "30284"
    },
    {
        "id": "wiki20220301en021_30404",
        "title": "Student's t-test",
        "content": "Paired samples t-tests are often referred to as \"dependent samples t-tests\". Calculations Explicit expressions that can be used to carry out various t-tests are given below. In each case, the formula for a test statistic that either exactly follows or closely approximates a t-distribution under the null hypothesis is given. Also, the appropriate degrees of freedom are given in each case. Each of these statistics can be used to carry out either a one-tailed or two-tailed test. Once the t value and degrees of freedom are determined, a p-value can be found using a table of values from Student's t-distribution. If the calculated p-value is below the threshold chosen for statistical significance (usually the 0.10, the 0.05, or 0.01 level), then the null hypothesis is rejected in favor of the alternative hypothesis. One-sample t-test In testing the null hypothesis that the sample mean is equal to a specified value , one uses the statistic",
        "contents": "Student's t-test. Paired samples t-tests are often referred to as \"dependent samples t-tests\". Calculations Explicit expressions that can be used to carry out various t-tests are given below. In each case, the formula for a test statistic that either exactly follows or closely approximates a t-distribution under the null hypothesis is given. Also, the appropriate degrees of freedom are given in each case. Each of these statistics can be used to carry out either a one-tailed or two-tailed test. Once the t value and degrees of freedom are determined, a p-value can be found using a table of values from Student's t-distribution. If the calculated p-value is below the threshold chosen for statistical significance (usually the 0.10, the 0.05, or 0.01 level), then the null hypothesis is rejected in favor of the alternative hypothesis. One-sample t-test In testing the null hypothesis that the sample mean is equal to a specified value , one uses the statistic",
        "wiki_id": "536080"
    },
    {
        "id": "Surgery_Schwartz_14027",
        "title": "Surgery_Schwartz",
        "content": "statistical testing requires declaration of a null hypothesis, usually corresponding to the “default” state (i.e., no difference or the patient is healthy). The alternative hypothesis would then negate the stated null hypothesis (i.e., there is a dif-ference or the patient is unhealthy). The result of a statistical significance test may either reject or accept the null hypothesis, and this result can correspond with the true state (a correct deci-sion) or not correspond with the true state (an error). Two types of error are possible (Table 51-3).Type I Error. A type I error occurs when the null hypothesis is rejected but is actually true in the population. This may also be referred to as a false positive. The type I error rate, denoted by the Greek letter α (alpha), is the probability that the null hypothesis is rejected given that it is true. The error rate may also be referred to as the significance level, and often a value of 0.05, or 5%, is frequently used in the literature.Type",
        "contents": "Surgery_Schwartz. statistical testing requires declaration of a null hypothesis, usually corresponding to the “default” state (i.e., no difference or the patient is healthy). The alternative hypothesis would then negate the stated null hypothesis (i.e., there is a dif-ference or the patient is unhealthy). The result of a statistical significance test may either reject or accept the null hypothesis, and this result can correspond with the true state (a correct deci-sion) or not correspond with the true state (an error). Two types of error are possible (Table 51-3).Type I Error. A type I error occurs when the null hypothesis is rejected but is actually true in the population. This may also be referred to as a false positive. The type I error rate, denoted by the Greek letter α (alpha), is the probability that the null hypothesis is rejected given that it is true. The error rate may also be referred to as the significance level, and often a value of 0.05, or 5%, is frequently used in the literature.Type"
    },
    {
        "id": "wiki20220301en024_39187",
        "title": "Alternative hypothesis",
        "content": "In the court, only legal evidence can be consider as the foundation for judge's trial. As for hypothesis testing, a reasonable test statistic should be set to measure the statistic significance of null hypothesis. If in certain significance level, the null hypothesis is demonstrated to be fault, the alternative hypothesis can be claim to be true. In order to quantify the statistic significance, the test statistic variables which follow certain probability distribution such as normal distribution, t-distribution is preferred hence to determine the\"probability of obtaining test results at least as extreme as the results actually observed, under the assumption that the null hypothesis is correct\", which is defined as p-value. If the p-value is smaller than the than the chosen significance level (α), it can be claim that observed data is sufficiently inconsistent with the null hypothesis and hence the null hypothesis may be rejected and the alternative hypothesis may be accepted. In",
        "contents": "Alternative hypothesis. In the court, only legal evidence can be consider as the foundation for judge's trial. As for hypothesis testing, a reasonable test statistic should be set to measure the statistic significance of null hypothesis. If in certain significance level, the null hypothesis is demonstrated to be fault, the alternative hypothesis can be claim to be true. In order to quantify the statistic significance, the test statistic variables which follow certain probability distribution such as normal distribution, t-distribution is preferred hence to determine the\"probability of obtaining test results at least as extreme as the results actually observed, under the assumption that the null hypothesis is correct\", which is defined as p-value. If the p-value is smaller than the than the chosen significance level (α), it can be claim that observed data is sufficiently inconsistent with the null hypothesis and hence the null hypothesis may be rejected and the alternative hypothesis may be accepted. In",
        "wiki_id": "645892"
    },
    {
        "id": "wiki20220301en011_96801",
        "title": "Pearson's chi-squared test",
        "content": "Sustain or reject the null hypothesis that the observed frequency distribution is the same as the theoretical distribution based on whether the test statistic exceeds the critical value of . If the test statistic exceeds the critical value of , the null hypothesis ( = there is no difference between the distributions) can be rejected, and the alternative hypothesis ( = there is a difference between the distributions) can be accepted, both with the selected level of confidence. If the test statistic falls below the threshold value, then no clear conclusion can be reached, and the null hypothesis is sustained (we fail to reject the null hypothesis), though not necessarily accepted.",
        "contents": "Pearson's chi-squared test. Sustain or reject the null hypothesis that the observed frequency distribution is the same as the theoretical distribution based on whether the test statistic exceeds the critical value of . If the test statistic exceeds the critical value of , the null hypothesis ( = there is no difference between the distributions) can be rejected, and the alternative hypothesis ( = there is a difference between the distributions) can be accepted, both with the selected level of confidence. If the test statistic falls below the threshold value, then no clear conclusion can be reached, and the null hypothesis is sustained (we fail to reject the null hypothesis), though not necessarily accepted.",
        "wiki_id": "226676"
    },
    {
        "id": "wiki20220301en130_34005",
        "title": "Bonferroni correction",
        "content": "Background The method is named for its use of the Bonferroni inequalities. An extension of the method to confidence intervals was proposed by Olive Jean Dunn. Statistical hypothesis testing is based on rejecting the null hypothesis if the likelihood of the observed data under the null hypotheses is low. If multiple hypotheses are tested, the chance of observing a rare event increases, and therefore, the likelihood of incorrectly rejecting a null hypothesis (i.e., making a Type I error) increases. The Bonferroni correction compensates for that increase by testing each individual hypothesis at a significance level of , where is the desired overall alpha level and is the number of hypotheses. For example, if a trial is testing hypotheses with a desired , then the Bonferroni correction would test each individual hypothesis at . Likewise, when constructing multiple confidence intervals the same phenomenon appears.",
        "contents": "Bonferroni correction. Background The method is named for its use of the Bonferroni inequalities. An extension of the method to confidence intervals was proposed by Olive Jean Dunn. Statistical hypothesis testing is based on rejecting the null hypothesis if the likelihood of the observed data under the null hypotheses is low. If multiple hypotheses are tested, the chance of observing a rare event increases, and therefore, the likelihood of incorrectly rejecting a null hypothesis (i.e., making a Type I error) increases. The Bonferroni correction compensates for that increase by testing each individual hypothesis at a significance level of , where is the desired overall alpha level and is the number of hypotheses. For example, if a trial is testing hypotheses with a desired , then the Bonferroni correction would test each individual hypothesis at . Likewise, when constructing multiple confidence intervals the same phenomenon appears.",
        "wiki_id": "7838811"
    }
]